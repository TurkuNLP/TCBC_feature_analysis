{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc89a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tenojo/miniconda3/envs/Test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from scripts import bookdatafunctions as bdf\n",
    "from scripts import corpusMLfunctions as cmf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b1b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "AGE_SHEET = \"ISBN_MAPS/ISBN2AGE.xlsx\"\n",
    "AUTH_SHEET = \"ISBN_MAPS/ISBN2AUTH.xlsx\"\n",
    "CONLLUS_FOLDER = \"Conllus\"\n",
    "SNIPPET_LENS = [5,10,25,50,75,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e62f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load corpus\n",
    "corpus = bdf.mapGroup2Age(bdf.maskPropn(bdf.initBooksFromConllus(CONLLUS_FOLDER)), AGE_SHEET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "060ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "#Generate train-test-eval split for keys\n",
    "author_level_split = cmf.splitOnAuthorLevel(list(corpus.keys()), AUTH_SHEET)\n",
    "train_target, test_target, eval_target = cmf.generateAgeStratificationAmounts(corpus, 0.7)\n",
    "#Genre targets for train for TCBC v1.0\n",
    "train_target[1] = 158\n",
    "train_target[2] = 32\n",
    "train_target[3] = 20\n",
    "#Genre targets for test for TCBC v1.0\n",
    "test_target[1] = 34\n",
    "test_target[2] = 7\n",
    "test_target[3] = 5\n",
    "\n",
    "print(sum(list(train_target.values()))-210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070fbe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDuplicates(trainkeys: list, testkeys:list):\n",
    "    for key in trainkeys:\n",
    "        if key in testkeys:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def checkGenres(trainkeys: list, correct_amounts: dict):\n",
    "    amounts = {1:0, 2:0, 3:0}\n",
    "    for key in trainkeys:\n",
    "        genre = int(key[-1])\n",
    "        amounts[genre] = amounts[genre] + 1\n",
    "    for key in correct_amounts:\n",
    "        if abs(correct_amounts[key]-amounts[key]) > 2:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def good_books_in_train(trainkeys, goods):\n",
    "    for g in goods:\n",
    "        if g in trainkeys:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def no_bad_books_in_train(trainkeys, bads):\n",
    "    for b in bads:\n",
    "        if b in trainkeys:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b38c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def doTrainTestEvalSplitSeriesLevel(author_level_split: dict[str,list[str]], train_target_amounts: dict[int,int], test_target_amounts: dict[int,int], eval_target_amounts: dict[int,int], good_train_books=None, bad_train_books=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function which splits a corpus into (roughly) stratified datasets for training, evaluation, and testing\n",
    "    \"\"\"\n",
    "    train_keys = good_train_books\n",
    "    test_keys = []\n",
    "    eval_keys = []\n",
    "    authors = list(author_level_split.keys())\n",
    "    #Shuffle the authors so we don't always end up with the same sets\n",
    "    random.shuffle(authors)\n",
    "    for author in authors:\n",
    "        keys_to_add = author_level_split[author]\n",
    "        #Don't do dupes!\n",
    "        keys_to_add = [x for x in keys_to_add if x not in good_train_books]\n",
    "        #Get dicts for age:number of entries\n",
    "        to_add = cmf.getNumOfEntriesPerAge(keys_to_add)\n",
    "        current_train = cmf.getNumOfEntriesPerAge(train_keys)\n",
    "        current_test = cmf.getNumOfEntriesPerAge(test_keys)\n",
    "        current_eval = cmf.getNumOfEntriesPerAge(eval_keys)\n",
    "\n",
    "        amounts = {1:0, 2:0, 3:0}\n",
    "        for key in train_keys:\n",
    "            genre = int(key[-1])\n",
    "            amounts[genre] = amounts[genre] + 1\n",
    "        keys_to_add_amounts = {1:0, 2:0, 3:0}\n",
    "        for key in keys_to_add:\n",
    "            genre = int(key[-1])\n",
    "            keys_to_add_amounts[genre] = keys_to_add_amounts[genre] + 1\n",
    "\n",
    "        #Use a flag to determine whether to return true or false\n",
    "        toset = 'train'\n",
    "        for age in to_add:\n",
    "            #If age not yet present in the train set, then immediately return True as we want to add the batch to Train \n",
    "            if not age in list(current_train.keys()) and no_bad_books_in_train(keys_to_add, bad_train_books):\n",
    "                toset = 'train'\n",
    "                break\n",
    "            if amounts[3]+keys_to_add_amounts[3]>20:\n",
    "                toset = 'test'\n",
    "                break \n",
    "            #If the target age has not yet been met, then continue to check rest of the ages before making any conclusions\n",
    "            if current_train[age] < train_target_amounts[age]:\n",
    "                continue\n",
    "            #If the target amount has been reached in Train, then if an age is not present in Eval, immediately add the batch there\n",
    "            if not age in list(current_eval.keys()):\n",
    "                toset = 'eval'\n",
    "                break\n",
    "            #If the target amount has been reached in Train and Eval, then if an age is not present in Test, immediately add the batch there\n",
    "            if not age in list(current_test.keys()):\n",
    "                toset = 'test'\n",
    "                break\n",
    "            #If all previous checks pass and Eval is underpopulated, then tentatively add the batch to TE, but see the remaining ages if stronger conditions are met\n",
    "            if current_eval[age] < eval_target_amounts[age]:\n",
    "                toset = 'eval'\n",
    "            #If all previous checks pass and Test is underpopulated, then tentatively add the batch to TE, but see the remaining ages if stronger conditions are met\n",
    "            elif current_test[age] < test_target_amounts[age]:\n",
    "                toset = 'test'\n",
    "            elif len(train_keys)+len(keys_to_add)>210:\n",
    "                toset = 'test'\n",
    "                break\n",
    "            #If all else passes, then just tentatively add the batch to train\n",
    "            else:\n",
    "                toset = 'train'\n",
    "        \n",
    "        if toset == 'train':\n",
    "            train_keys += keys_to_add\n",
    "        elif toset == 'eval':\n",
    "            eval_keys += keys_to_add\n",
    "        else:\n",
    "            test_keys += keys_to_add\n",
    "    return train_keys, test_keys, eval_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50889db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def doTrainTestEvalSplitNoSeriesLevel(book_ids, train_target_amounts: dict[int,int], test_target_amounts: dict[int,int]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function which splits a corpus into (roughly) stratified datasets for training, evaluation, and testing\n",
    "    \"\"\"\n",
    "    train_keys = []\n",
    "    test_keys = []\n",
    "    eval_keys = []\n",
    "\n",
    "    current_train = {x:0 for x in train_target_amounts.keys()}\n",
    "    current_test = {x:0 for x in test_target_amounts.keys()}\n",
    "    #Shuffle the authors so we don't always end up with the same sets\n",
    "    random.shuffle(book_ids)\n",
    "    for book in book_ids:\n",
    "        #Append based on age and genre\n",
    "        age = int(bdf.findAgeFromID(book))\n",
    "        genre = int(book[-1])\n",
    "        if current_train.get(age, 0)+1<=train_target_amounts[age] and current_train[genre]+1<=train_target_amounts[genre]:\n",
    "            train_keys.append(book)\n",
    "            current_train[age] = current_train[age]+1\n",
    "            current_train[genre] = current_train[genre]+1\n",
    "        elif current_test.get(age, 0)+1<=test_target_amounts[age] and current_test[genre]+1<=test_target_amounts[genre]:\n",
    "            test_keys.append(book)\n",
    "            current_test[age] = current_test[age]+1\n",
    "            current_test[genre] = current_test[genre]+1\n",
    "        else:\n",
    "            eval_keys.append(book)\n",
    "    return train_keys, test_keys, eval_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "trainkeys_straps = []\n",
    "testkeys_straps = []\n",
    "evalkeys_straps = []\n",
    "\n",
    "#After getting further into this rabbit hole, I want to test if we can generate straps that include/exclude these books:\n",
    "\n",
    "good_train_books = ['9789527337905_15_2', '9789510350843_13_3', '9789526309330_14_3', '9789526308616_13_3', '9789526308623_14_3', '9789526310053_15_3', '9789526308630_15_3']\n",
    "bad_train_books = ['9789523560772_14_1', '9789523563841_14_1', '9789523564954_13_1', '9789523990234_12_1', '9789511349938_12_1', '9789511349945_12_1', '9789511252825_13_3', '9789511307143_14_3', '9789511347552_7_3', '9789511383604_8_3', '9789510427927_7_1']\n",
    "\n",
    "only_novels = [x for x in list(corpus.keys()) if x[-1]=='1']\n",
    "\n",
    "while len(trainkeys_straps) != 100:\n",
    "    train_keys, test_keys, eval_keys = doTrainTestEvalSplitNoSeriesLevel(only_novels, train_target, test_target)\n",
    "    if checkDuplicates(train_keys, test_keys+eval_keys):\n",
    "        trainkeys_straps.append(train_keys)\n",
    "        testkeys_straps.append(test_keys)\n",
    "        evalkeys_straps.append(eval_keys)\n",
    "        print(len(trainkeys_straps)+1)\n",
    "    else:\n",
    "        amounts = {1:0, 2:0, 3:0}\n",
    "        for key in train_keys:\n",
    "            genre = int(key[-1])\n",
    "            amounts[genre] = amounts[genre] + 1\n",
    "        pprint(amounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d2b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x in trainkeys_straps:\n",
    "    for y in trainkeys_straps:\n",
    "        if x==y:\n",
    "            counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2456bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = []\n",
    "for i in range(len(trainkeys_straps)):\n",
    "    temp_dict.append({'id':i, 'train_keys':trainkeys_straps[i], 'eval_keys':evalkeys_straps[i], 'test_keys':testkeys_straps[i]})\n",
    "with open(\"NewKeylists_only_novels.jsonl\", 'w') as f:\n",
    "    f.write('\\n'.join(map(json.dumps, temp_dict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
